{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merchant Ranking Algorith\n",
    "The method of ranking each merchant, will take inspiration from the methods proposed in (https://sapinsider.org/leveraging-analytical-method-for-ranking-suppliers/), in which we rank each key attribute out of 5, then sum them together with weightsget a score for each merchant. \n",
    "\n",
    "The Key Attributes for now are: \n",
    "- Merchant's BNPL Revenue\n",
    "- Proportion of 'identified' Fraud transactions\n",
    "- The customer Base \n",
    "- Projected Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml import feature as H\n",
    "# First lets reed the datasets\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Data_Explorer\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tansaction_Revenue\n",
    "For this we will take:\n",
    "- Total_BNPL_Revenue\n",
    "- Average_BNPL_Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = spark.read.parquet('../data/processed/transactions')\n",
    "merchants =  spark.read.parquet('../data/processed/merchants/')\n",
    "full_dataset = spark.read.parquet('../data/curated/full_dataset/')\n",
    "final_data_collection = merchants.select('merchant_abn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_collection = final_data_collection.join(full_dataset.where(F.col('Potential_outlier') == False).groupBy('merchant_abn').agg(F.round(F.sum('BNPL_Revenue'), 2).alias('Total_BNPL_Revenue'), F.round(F.sum('dollar_value'), 2).alias('Total_Dollar_value'), F.count('BNPL_Revenue').alias('Total_Transactions')), on=['merchant_abn'])\n",
    "# now add last 6 months\n",
    "final_data_collection = final_data_collection.join(full_dataset.where((F.col('order_datetime') > F.lit('2022-03-01')) & (F.col('Potential_outlier') == False)).groupBy('merchant_abn').agg(F.round(F.sum('BNPL_Revenue'), 2).alias('Total_BNPL_Revenue_6MON'), F.round(F.sum('dollar_value'), 2).alias('Total_Dollar_value_6MON'), F.count('BNPL_Revenue').alias('Total_Transactions_6MON')), on=['merchant_abn'])\n",
    "# now add fraud attributes\n",
    "final_data_collection = final_data_collection.join(full_dataset.where(F.col('Potential_outlier') == True).groupBy('merchant_abn').agg(F.round(F.sum('BNPL_Revenue'), 2).alias('Total_BNPL_Revenue_Fraud'), F.count('BNPL_Revenue').alias('Total_Transactions_Fraud'), F.round(F.sum('dollar_value'), 2).alias('Total_Dollar_value_Fraud')), on=['merchant_abn'])\n",
    "final_data_collection = final_data_collection.join(full_dataset.where((F.col('order_datetime') > F.lit('2022-03-01')) & (F.col('Potential_outlier') == True)).groupBy('merchant_abn').agg(F.round(F.sum('BNPL_Revenue'), 2).alias('Total_BNPL_Revenue_6MON_Fraud'), F.count('BNPL_Revenue').alias('Total_Transactions_6MON_Fraud'), F.round(F.sum('dollar_value'), 2).alias('Total_Dollar_value_6MON_Fraud')), on=['merchant_abn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proportion values\n",
    "final_data_collection = final_data_collection.withColumn('Total_BNPL_Revenue_FP', F.col('Total_BNPL_Revenue_Fraud') / (F.col('Total_BNPL_Revenue') + F.col('Total_BNPL_Revenue_Fraud')))\n",
    "final_data_collection = final_data_collection.withColumn('Total_Dollar_value_FP', F.col('Total_BNPL_Revenue_Fraud') / (F.col('Total_Dollar_value') + F.col('Total_BNPL_Revenue_Fraud')))\n",
    "final_data_collection = final_data_collection.withColumn('Total_Transactions_FP', F.col('Total_Transactions_Fraud') / (F.col('Total_Transactions') + F.col('Total_Transactions_Fraud')))\n",
    "final_data_collection = final_data_collection.withColumn('Total_BNPL_Revenue_6MON_FP', F.col('Total_BNPL_Revenue_6MON_Fraud') / (F.col('Total_BNPL_Revenue_6MON') + F.col('Total_BNPL_Revenue_6MON_Fraud')))\n",
    "final_data_collection = final_data_collection.withColumn('Total_Dollar_value_6MON_FP', F.col('Total_BNPL_Revenue_6MON_Fraud') / (F.col('Total_Dollar_value_6MON') + F.col('Total_BNPL_Revenue_6MON_Fraud')))\n",
    "final_data_collection = final_data_collection.withColumn('Total_Transactions_6MON_FP', F.col('Total_Transactions_6MON_Fraud') / (F.col('Total_Transactions_6MON') + F.col('Total_Transactions_6MON_Fraud')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_collection = final_data_collection.select('merchant_abn', 'Total_BNPL_Revenue', 'Total_Dollar_value', 'Total_Transactions', 'Total_BNPL_Revenue_6MON', 'Total_Dollar_value_6MON', 'Total_Transactions_6MON', 'Total_BNPL_Revenue_FP', 'Total_Dollar_value_FP', 'Total_Transactions_FP', 'Total_BNPL_Revenue_6MON_FP', 'Total_Dollar_value_6MON_FP', 'Total_Transactions_6MON_FP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for col_name in final_data_collection.columns[1:]:\n",
    "    values = final_data_collection.select(F.max(col_name).alias('high'), F.min(col_name).alias('low'))\n",
    "    final_data_collection = final_data_collection.withColumn(col_name, (F.col(col_name) - values.select('low').head()[0]) / (values.select('high').head()[0] - values.select('low').head()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to perform Revenue and Risk score\n",
    "final_data_collection = final_data_collection.withColumn('Revenue_Score', F.col('Total_BNPL_Revenue') + F.col('Total_Dollar_value') + F.col('Total_Transactions') +\n",
    "                                                  F.col('Total_BNPL_Revenue_6MON') + F.col('Total_Dollar_value_6MON') + F.col('Total_Transactions_6MON'))\n",
    "# And Risk Revenue score \n",
    "final_data_collection = final_data_collection.withColumn('Risk_Revenue_Score', -1 * (F.col('Total_BNPL_Revenue_FP') + F.col('Total_Dollar_value_FP') + F.col('Total_Transactions_FP') +\n",
    "                                                  F.col('Total_BNPL_Revenue_6MON_FP') + F.col('Total_Dollar_value_6MON_FP') + F.col('Total_Transactions_6MON_FP')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_collection = final_data_collection.select(['merchant_abn', 'Revenue_Score', 'Risk_Revenue_Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merchant Sustainability\n",
    "Next, we add a rating for a companies growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchants_sub = merchants.select(['merchant_abn', 'avg_monthly_inc', 'postcode_entropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in merchants_sub.columns[1:]:\n",
    "    values = merchants_sub.select(F.max(col_name).alias('high'), F.min(col_name).alias('low'))\n",
    "    merchants_sub = merchants_sub.withColumn(col_name, (F.col(col_name) - values.select('low').head()[0]) / (values.select('high').head()[0] - values.select('low').head()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchants_sub = merchants_sub.withColumn('Sustainability_score', F.col('avg_monthly_inc') - F.col('postcode_entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchants_sub = merchants_sub.select(['merchant_abn', 'Sustainability_score'])\n",
    "final_data_collection = final_data_collection.join(merchants_sub, on=['merchant_abn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Rankings\n",
    "In this sections we use the features:\n",
    "- customer_loyalty_agg\n",
    "- unique_cust\n",
    "- Fraud_cust\n",
    "- Cust_tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3886:>                                                       (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 04:46:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 04:46:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 04:46:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 04:46:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 04:46:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3892:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+---------+\n",
      "|user_id|merchant_abn|retention|\n",
      "+-------+------------+---------+\n",
      "|      1| 13118172970|     87.0|\n",
      "|      1| 16644129035|    365.0|\n",
      "|      1| 22953464223|    365.0|\n",
      "+-------+------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create Loyalfy feature\n",
    "grouped = full_dataset.groupBy(\"user_id\", \"merchant_abn\")\n",
    "RPR = grouped.count().withColumnRenamed(\"count\", \"RPR\")\n",
    "upSell = RPR.groupBy(\"user_id\").count().withColumnRenamed(\"count\", \"upsell\")\n",
    "CLV = grouped.sum(\"dollar_value\").withColumnRenamed(\"sum(dollar_value)\", \"CLV\")\n",
    "# Define the window\n",
    "from pyspark.sql.window import Window\n",
    "w = Window.partitionBy([\"user_id\", \"merchant_abn\"]).orderBy(\"order_datetime\")\n",
    "\n",
    "retention = full_dataset.withColumn(\n",
    "    'diff',\n",
    "    F.datediff(F.col(\"order_datetime\"), F.lag(\"order_datetime\").over(w))\n",
    ").groupBy(\"user_id\", \"merchant_abn\").agg(F.avg(F.col(\"diff\")).alias(\"retention\"))\n",
    "retention.agg({\"retention\":\"max\"}).collect()\n",
    "retention.na.fill(value=365)\n",
    "loyal = retention.na.fill(value=365).join(RPR, on=[\"user_id\", \"merchant_abn\"], how=\"left\").join(CLV, on=[\"user_id\", \"merchant_abn\"], how=\"left\").join(upSell, on=[\"user_id\"], how=\"left\")\n",
    "loyal = loyal.withColumn(\"loyal\", F.col(\"RPR\") * F.col(\"CLV\") * F.col(\"upSell\") / F.col(\"retention\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "loyal = loyal.select(*(col(c).cast(\"float\").alias(c) for c in loyal.columns))\n",
    "loyal = loyal.select('user_id', 'merchant_abn', 'loyal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to dataset\n",
    "# full_dataset = full_dataset.join(loyal, on=['user_id', 'merchant_abn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_attr =  full_dataset.groupBy('merchant_abn').agg(F.countDistinct('user_id').alias('Unique_Customers'), F.round(F.count('user_id') / F.countDistinct('user_id'), 2).alias('Transaction_per_User'), F.round(F.avg('Proportion_Unreg_Merchant_Transactions'),2).alias('Customer_Defects'), F.round(F.avg('Average taxable income or loss'),2).alias('customer_wealth'), F.round(F.avg('loyal'),2).alias('loyalty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4171:>                                                       (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 05:01:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:01:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:01:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4213:>                                                       (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 05:01:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:01:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:01:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4255:>                                                       (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 05:03:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:03:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:03:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:03:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:03:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4484:======>                                                 (1 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 05:09:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4484:=======>        (4 + 5) / 9][Stage 4486:========>       (5 + 3) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 05:09:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4525:>               (0 + 8) / 9][Stage 4527:>               (0 + 0) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 05:10:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:10:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:10:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4525:=>              (1 + 8) / 9][Stage 4527:>               (0 + 0) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 05:10:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:10:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4575:>               (0 + 8) / 9][Stage 4577:>               (0 + 0) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 05:12:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:12:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:12:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/06 05:12:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4575:=====>          (3 + 6) / 9][Stage 4577:>               (0 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 05:12:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for col_name in customer_attr.columns[1:]:\n",
    "    values = customer_attr.select(F.max(col_name).alias('high'), F.min(col_name).alias('low'))\n",
    "    customer_attr = customer_attr.withColumn(col_name, (F.col(col_name) - values.select('low').head()[0]) / (values.select('high').head()[0] - values.select('low').head()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
