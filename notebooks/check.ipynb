{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.18.71.108:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Checker</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f83650abc70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = SparkSession.builder.appName(\"Checker\").getOrCreate()\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------+--------------+-----------+\n",
      "|user_id|merchant_abn|dollar_value|order_datetime|   order_id|\n",
      "+-------+------------+------------+--------------+-----------+\n",
      "|  14935| 79417999332|      136.07|    2021-11-26|68719476736|\n",
      "|      1| 46451548968|       72.62|    2021-11-26|68719476737|\n",
      "|  14936| 89518629617|        3.08|    2021-11-26|68719476738|\n",
      "+-------+------------+------------+--------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans = sp.read.option(\"inferSchema\", True).parquet(\"../data/curated/transactions\")\n",
    "trans.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- merchant_abn: long (nullable = true)\n",
      " |-- dollar_value: float (nullable = true)\n",
      " |-- order_datetime: date (nullable = true)\n",
      " |-- order_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description for the function is below\n",
    "def potential_outlier(full_dataset):\n",
    "    '''\n",
    "    # Outlier detection algorithm\n",
    "\n",
    "    This will be inplemented by creating an attribute called 'potential outlier'. which marks dollar \n",
    "    values of transactios that fall out of a companies specific SIQR as True, and False otherwise. \n",
    "    Furthermore, it marks all transactions that belong to a company, which has no variance \n",
    "    in the dollar value of respective transactios. This is due to it being unrealistic/dodgy.\n",
    "    \n",
    "    Note: after further investigating the 'dodgy' transactions, consistent dollar values for all merchant's \n",
    "    should be reconsidered, as some fall under the 'tv subscription' description, which should be consistent\n",
    "    anyway\n",
    "    '''\n",
    "    # In a similar method to the boxplot, we use the SIQR to identify outliers\n",
    "    # see https://towardsdatascience.com/outlier-detection-part-2-6839f6199768\n",
    "    Fst_percentile = F.expr('percentile_approx(dollar_value, 0.25)')\n",
    "    Trd_percentile = F.expr('percentile_approx(dollar_value, 0.75)')\n",
    "    Second_percentile = F.expr('percentile_approx(dollar_value, 0.5)')\n",
    "    Outlier_tags = full_dataset.groupBy('merchant_abn').agg(Fst_percentile.alias('1_val'), Trd_percentile.alias('3_val'), Second_percentile.alias('2_val'), F.count('dollar_value').alias('Count'))\n",
    "    Outlier_tags = Outlier_tags.withColumn('SIQR_Lower', F.col('2_val') - F.col('1_val'))\n",
    "    Outlier_tags = Outlier_tags.withColumn('SIQR_Upper', F.col('3_val') - F.col('2_val'))\n",
    "    # Now calculate the limits\n",
    "    Outlier_tags = Outlier_tags.withColumn('Upper_limit', F.col('3_val') + 3 * F.col('SIQR_Upper'))\n",
    "    Outlier_tags = Outlier_tags.withColumn('Lower_limit', F.col('1_val') - 3 * F.col('SIQR_Lower'))\n",
    "    # after noticing that some merchants only have one transaction value (i.e one dollar_value amount for all transactios)\n",
    "    # decided to removed due to unrealisic distributed data \n",
    "    Outlier_tags = Outlier_tags.withColumn('Natural_var', F.when((F.col('Upper_limit') == F.col('Lower_limit')) & (F.col('Count') > 10), True).otherwise(False))\n",
    "    Outlier_tags = Outlier_tags.select('merchant_abn', 'Upper_limit', 'Lower_limit', 'Natural_var')\n",
    "    # Now all we need to do is join this data to each transaction, then can select the transactios which are (not) within the limits\n",
    "    Outlier_tags = full_dataset.select('merchant_abn', 'order_id', 'user_id', 'dollar_value').join(Outlier_tags, on= ['merchant_abn'])\n",
    "    # finally identify the outliers which fall out of distribution or apart of a dodgy business\n",
    "    Outlier_tags = Outlier_tags.withColumn('Potential_Outlier', F.when((Outlier_tags.dollar_value <= F.col('Upper_limit')) & (Outlier_tags.dollar_value >= F.col('Lower_limit')) & (F.col('Natural_var') == False), False)\n",
    "                                                .otherwise(True))\n",
    "    # Join the new attributes obtained above to the transaction spark dataframe\n",
    "    Outlier_tags = Outlier_tags.select(['order_id', 'Natural_var', 'Potential_Outlier'])\n",
    "    full_dataset = full_dataset.join(Outlier_tags, on='order_id')\n",
    "    return full_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('virtual-p2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcf6849838b3a8621666e21fdc4cc1583090fffb5f1906a909fbc1c95ae1bb65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
