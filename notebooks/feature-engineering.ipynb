{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- TO DELETE ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['2021-03-08','2021-04-02','2021-04-03','2021-04-04','2021-04-05','2021-04-25','2021-06-14','2021-09-24','2021-11-02','2021-12-25','2021-12-26','2021-12-27','2021-12-28',\n",
    "       '2022-01-01','2022-01-03','2022-01-26','2022-03-14','2022-04-15','2022-04-16','2022-04-17','2022-04-18','2022-04-25',\n",
    "       '2022-06-13','2022-09-22','2022-09-23']\n",
    "dates = pd.date_range(start='2021-02-01', end='2022-10-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import re\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 23:57:05 WARN Utils: Your hostname, J-L resolves to a loopback address: 127.0.1.1; using 172.18.71.108 instead (on interface eth0)\n",
      "22/10/04 23:57:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 23:57:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/04 23:57:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/10/04 23:57:08 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.18.71.108:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FE-extras</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbfdc2593a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = SparkSession.builder.appName(\"FE-extras\").getOrCreate()\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for date in dates:\n",
    "    if date in data:\n",
    "        list1.append((date.strftime('%Y-%m-%d'), 1))\n",
    "    else:\n",
    "        list1.append((date.strftime('%Y-%m-%d'), 0))\n",
    "holiday_data = sp.createDataFrame(pd.DataFrame(list1, columns =['date', 'holiday']))\n",
    "holiday_data = holiday_data.withColumn(\"date\",col(\"date\").cast(DateType()))\n",
    "# print(holiday_data.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|      date|holiday|\n",
      "+----------+-------+\n",
      "|2021-02-01|      0|\n",
      "|2021-02-02|      0|\n",
      "+----------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "holiday_data.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data.write.parquet(\"../data/tables/holiday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Administrative_Support_Services= [\"equipment tool furniture appliance rent al leasing\", \"florist supply nursery stock flower\", \"lawn garden supply outlet including nursery\"]\n",
    "Personal_Services= [\"shoe shop\", \"gift card novelty souvenir shop\", \"antique shop sale repair restoration service\", \"watch clock jewellery repair shop\", \"jewellery watch clock silverware shop\",  \"motor vehicle supply new part\", \"furniture home furnishing equipment shop manufa...\", \"tent awning shop\", \"optician optical good eyeglass\"]\n",
    "Arts_Recreation_Services = [\"digital good book movie music\", \"music shop musical instrument piano sheet music\", \"health beauty spa\", \"bicycle shop sale service\", \"art dealer gallery\", \"hobby toy game shop\", \"stationery office supply printing writing paper\"]\n",
    "Information_Media_Telecommunications = [\"telecom\", \"computer programming data processing integrated...\", \"book periodical newspaper\", \"artist supply craft shop\", \"computer computer peripheral equipment software\", \"cable satellite pay television radio service\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = []\n",
    "tags = []\n",
    "for ele in Administrative_Support_Services:\n",
    "    desc.append(\"Administrative_Support_Services\")\n",
    "tags += Administrative_Support_Services\n",
    "for ele in Personal_Services:\n",
    "    desc.append(\"Personal_Services\")\n",
    "tags += Personal_Services\n",
    "for ele in Arts_Recreation_Services:\n",
    "    desc.append(\"Arts_Recreation_Services\")\n",
    "tags += Arts_Recreation_Services\n",
    "for ele in Information_Media_Telecommunications:\n",
    "    desc.append(\"Information_Media_Telecommunications\")\n",
    "tags += Information_Media_Telecommunications\n",
    "\n",
    "to_df = {\n",
    "    \"sector\" :  desc,\n",
    "    \"Description\" : tags\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = sp.createDataFrame(pd.DataFrame(to_df))\n",
    "dataset = dataset.join(sectors, ['Description'])\n",
    "dataset.createOrReplaceTempView('data')\n",
    "dataset = dataset.join(spark.sql(\"\"\"select sector, avg(description_avg) as sector_avg from data group by sector\"\"\"), ['sector'])\n",
    "dataset.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[sector: string, entry_rate: string, exit_rate: string, survival_rate: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [['Administrative_Support_Services','21.3','15.9','58.9'],['Personal_Services','16.9','12.8','65.7'],['Arts_Recreation_Services','17.3','13.1','63.8'],['Information_Media_Telecommunications','18.6','14.8','59.8']]\n",
    "industry_trends=pd.DataFrame(data, columns=['sector','entry_rate','exit_rate','survival_rate'])\n",
    "industry_trends = sp.createDataFrame(industry_trends)\n",
    "industry_trends.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+-------------+\n",
      "|              sector|entry_rate|exit_rate|survival_rate|\n",
      "+--------------------+----------+---------+-------------+\n",
      "|Administrative_Su...|      21.3|     15.9|         58.9|\n",
      "|   Personal_Services|      16.9|     12.8|         65.7|\n",
      "|Arts_Recreation_S...|      17.3|     13.1|         63.8|\n",
      "|Information_Media...|      18.6|     14.8|         59.8|\n",
      "+--------------------+----------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "industry_trends.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_trends.write.parquet(\"../data/tables/sector_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+-------------+\n",
      "|              sector|entry_rate|exit_rate|survival_rate|\n",
      "+--------------------+----------+---------+-------------+\n",
      "|Information_Media...|      18.6|     14.8|         59.8|\n",
      "|Administrative_Su...|      21.3|     15.9|         58.9|\n",
      "|Arts_Recreation_S...|      17.3|     13.1|         63.8|\n",
      "|   Personal_Services|      16.9|     12.8|         65.7|\n",
      "+--------------------+----------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sectors = sp.read.option(\"inferSchema\", True).parquet(\"../data/tables/sector_data/\")\n",
    "sectors.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('virtual-p2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcf6849838b3a8621666e21fdc4cc1583090fffb5f1906a909fbc1c95ae1bb65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
