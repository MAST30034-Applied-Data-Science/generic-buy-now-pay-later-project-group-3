{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run \"ETL\" script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Spark session \n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Data_Explorer\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read the files \n",
    "transactions_sample = spark.read.parquet('../data/tables/transactions_20210828_20220227_snapshot')\n",
    "transactions_sample2 = spark.read.parquet('../data/tables/transactions_20210228_20210827_snapshot')\n",
    "transactions_sample3 = spark.read.parquet('../data/tables/transactions_20220228_20220828_snapshot')\n",
    "transactions_sample.unionByName(transactions_sample2, True)\n",
    "transactions_sample.unionByName(transactions_sample3, True)\n",
    "consumer_details = spark.read.parquet('../data/tables/consumer_user_details.parquet')\n",
    "merchants_tbl = spark.read.parquet('../data/tables/tbl_merchants.parquet')\n",
    "customer_tbl = spark.read.option(\"delimiter\", \"|\").option(\"header\",True).csv('../data/tables/tbl_consumer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchants = merchants_tbl.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# this function standardises the tags attribute, creating a list with the 'description', 'revenue band' and 'BNPL service charge'\n",
    "def tag_extract(tag_string): \n",
    "    # first need to preprocess\n",
    "    string =  re.sub('\\[','(', tag_string.lower())\n",
    "    string = re.sub('\\]',')', string)\n",
    "    # break the string into sections\n",
    "    string_cut = string.split('),')\n",
    "    new_string = []\n",
    "    # first extract the description \n",
    "    new_string.append(str(string_cut[0].strip('((')))\n",
    "    # second extract the band\n",
    "    new_string.append(str(re.search(r'[a-z]',string_cut[1]).group()))\n",
    "    # finally the take rate\n",
    "    new_string.append(float(re.search(r'[0-9]+\\.[0-9]+',string_cut[2]).group()))\n",
    "    return(new_string)\n",
    "################\n",
    "# now we can run the algorithm\n",
    "tags = merchants['tags']\n",
    "processed_tags = []\n",
    "for i in tags:\n",
    "    processed_tags.append(tag_extract(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "merchant_tbl = pd.DataFrame(processed_tags, columns=('Description', 'Earnings_Class', 'BNPL_Fee'))\n",
    "merchant_tbl = pd.concat([merchants, merchant_tbl], axis=1)\n",
    "# drop the tags column \n",
    "merchant_tbl.drop(columns='tags', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and convert back to spark dataframe \n",
    "merchants_tbl = spark.createDataFrame(merchant_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be further expanded in breaking the discription up further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tbl = customer_tbl.join(consumer_details, ['consumer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = transactions_sample.join(customer_tbl, ['user_id'])\n",
    "merchants_tbl = merchants_tbl.withColumnRenamed('name','company_name')\n",
    "full_dataset = full_dataset.join(merchants_tbl, ['merchant_abn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add a day (mon,...), weekly & monthly attribute\n",
    "import pyspark.sql.functions as F\n",
    "full_dataset = full_dataset.withColumn('Day', F.dayofweek('order_datetime'))\n",
    "full_dataset = full_dataset.withColumn('Month', F.month('order_datetime'))\n",
    "# now we can also add the bnpl revenue from a transaction \n",
    "full_dataset = full_dataset.withColumn('BNPL_Revenue', F.col('dollar_value') * 0.01 * F.col('BNPL_Fee'))\n",
    "full_dataset.createOrReplaceTempView('data')\n",
    "# we can remove name, location and customerID for now, due to being unnnesesary attributes (although company_name could also be removed)\n",
    "full_dataset = spark.sql(\"\"\"\n",
    "select merchant_abn, user_id, dollar_value, order_id, order_datetime, state, postcode, gender, company_name, \n",
    "        Description, Earnings_Class, BNPL_Fee, BNPL_Revenue, Day, Month, weekofyear(order_datetime) as weekofyear from data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardisation of Customers \n",
    "The objective of this section is to verify if a customer's details have been recorded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# dataset link \n",
    "link = 'https://www.matthewproctor.com/Content/postcodes/australian_postcodes.csv'\n",
    "postcodes = pd.read_csv(\"../data/tables/australian_postcodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes['postcode'] = postcodes['postcode'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust = customer_tbl.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumer_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1195503</td>\n",
       "      <td>Yolanda Williams</td>\n",
       "      <td>413 Haney Gardens Apt. 742</td>\n",
       "      <td>WA</td>\n",
       "      <td>6935</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179208</td>\n",
       "      <td>Mary Smith</td>\n",
       "      <td>3764 Amber Oval</td>\n",
       "      <td>NSW</td>\n",
       "      <td>2782</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1194530</td>\n",
       "      <td>Jill Jones MD</td>\n",
       "      <td>40693 Henry Greens</td>\n",
       "      <td>NT</td>\n",
       "      <td>862</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154128</td>\n",
       "      <td>Lindsay Jimenez</td>\n",
       "      <td>00653 Davenport Crossroad</td>\n",
       "      <td>NSW</td>\n",
       "      <td>2780</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>712975</td>\n",
       "      <td>Rebecca Blanchard</td>\n",
       "      <td>9271 Michael Manors Suite 651</td>\n",
       "      <td>WA</td>\n",
       "      <td>6355</td>\n",
       "      <td>Female</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499994</th>\n",
       "      <td>1385608</td>\n",
       "      <td>Jessica Avila</td>\n",
       "      <td>508 Miranda Overpass Apt. 218</td>\n",
       "      <td>QLD</td>\n",
       "      <td>4400</td>\n",
       "      <td>Female</td>\n",
       "      <td>499995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>1466964</td>\n",
       "      <td>Steven Thornton</td>\n",
       "      <td>7913 Schwartz Mission Suite 483</td>\n",
       "      <td>VIC</td>\n",
       "      <td>3097</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>499996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>1253484</td>\n",
       "      <td>Christy Smith</td>\n",
       "      <td>5681 Zachary Mountain Apt. 060</td>\n",
       "      <td>NSW</td>\n",
       "      <td>2756</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>499997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>175005</td>\n",
       "      <td>Donna Sutton</td>\n",
       "      <td>54140 Jacob Point</td>\n",
       "      <td>VIC</td>\n",
       "      <td>3989</td>\n",
       "      <td>Female</td>\n",
       "      <td>499998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>746835</td>\n",
       "      <td>Hannah Wilkins</td>\n",
       "      <td>61055 Long Valley</td>\n",
       "      <td>NSW</td>\n",
       "      <td>1755</td>\n",
       "      <td>Female</td>\n",
       "      <td>499999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499999 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       consumer_id               name                          address state  \\\n",
       "0          1195503   Yolanda Williams       413 Haney Gardens Apt. 742    WA   \n",
       "1           179208         Mary Smith                  3764 Amber Oval   NSW   \n",
       "2          1194530      Jill Jones MD               40693 Henry Greens    NT   \n",
       "3           154128    Lindsay Jimenez        00653 Davenport Crossroad   NSW   \n",
       "4           712975  Rebecca Blanchard    9271 Michael Manors Suite 651    WA   \n",
       "...            ...                ...                              ...   ...   \n",
       "499994     1385608      Jessica Avila    508 Miranda Overpass Apt. 218   QLD   \n",
       "499995     1466964    Steven Thornton  7913 Schwartz Mission Suite 483   VIC   \n",
       "499996     1253484      Christy Smith   5681 Zachary Mountain Apt. 060   NSW   \n",
       "499997      175005       Donna Sutton                54140 Jacob Point   VIC   \n",
       "499998      746835     Hannah Wilkins                61055 Long Valley   NSW   \n",
       "\n",
       "       postcode       gender  user_id  \n",
       "0          6935       Female        1  \n",
       "1          2782       Female        2  \n",
       "2           862       Female        3  \n",
       "3          2780       Female        4  \n",
       "4          6355       Female        5  \n",
       "...         ...          ...      ...  \n",
       "499994     4400       Female   499995  \n",
       "499995     3097  Undisclosed   499996  \n",
       "499996     2756  Undisclosed   499997  \n",
       "499997     3989       Female   499998  \n",
       "499998     1755       Female   499999  \n",
       "\n",
       "[499999 rows x 7 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes_sub = postcodes[['postcode', 'state', 'sa3name', 'sa4name', 'SA3_NAME_2016', 'electoraterating', 'electorate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1526/4267365078.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  postcodes_sub[\"sa3name\"] = postcodes_sub.groupby(\"state\")[\"sa3name\"].transform(lambda x: x.fillna(x.mode()))\n",
      "/tmp/ipykernel_1526/4267365078.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  postcodes_sub[\"sa4name\"] = postcodes_sub.groupby(\"state\")[\"sa4name\"].transform(lambda x: x.fillna(x.mode()))\n",
      "/tmp/ipykernel_1526/4267365078.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  postcodes_sub[\"SA3_NAME_2016\"] = postcodes_sub.groupby(\"state\")[\"SA3_NAME_2016\"].transform(lambda x: x.fillna(x.mode()))\n",
      "/tmp/ipykernel_1526/4267365078.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  postcodes_sub[\"electoraterating\"] = postcodes_sub.groupby(\"state\")[\"electoraterating\"].transform(lambda x: x.fillna(x.mode()))\n"
     ]
    }
   ],
   "source": [
    "# First imputate missing values\n",
    "postcodes_sub[\"sa3name\"] = postcodes_sub.groupby(\"state\")[\"sa3name\"].transform(lambda x: x.fillna(x.mode()))\n",
    "postcodes_sub[\"sa4name\"] = postcodes_sub.groupby(\"state\")[\"sa4name\"].transform(lambda x: x.fillna(x.mode()))\n",
    "postcodes_sub[\"SA3_NAME_2016\"] = postcodes_sub.groupby(\"state\")[\"SA3_NAME_2016\"].transform(lambda x: x.fillna(x.mode()))\n",
    "postcodes_sub[\"electoraterating\"] = postcodes_sub.groupby(\"state\")[\"electoraterating\"].transform(lambda x: x.fillna(x.mode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        Woden\n",
       "1                          NaN\n",
       "2                  Darwin City\n",
       "3                  Darwin City\n",
       "4                  Darwin City\n",
       "                 ...          \n",
       "18437    Brisbane Inner - West\n",
       "18438    Brisbane Inner - West\n",
       "18439                   Nundah\n",
       "18440         Surfers Paradise\n",
       "18441           Melbourne City\n",
       "Name: sa3name, Length: 18442, dtype: object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcodes_sub.groupby(\"state\")[\"sa3name\"].transform(lambda x: x.fillna(x.mode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "postcode               0\n",
       "state                  0\n",
       "sa3name              397\n",
       "sa4name              397\n",
       "SA3_NAME_2016        177\n",
       "electoraterating    1502\n",
       "electorate             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcodes_sub.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes_agg = postcodes_sub.groupby(['state', 'postcode'], as_index=False).agg(sa3name = pd.NamedAgg('sa3name',lambda x: pd.Series.mode(x) if len(pd.Series.mode(x))>0 else np.NaN),\n",
    "                                                 sa4name = pd.NamedAgg('sa4name',lambda x: pd.Series.mode(x) if len(pd.Series.mode(x))>0 else np.NaN),\n",
    "                                                 electoraterating = pd.NamedAgg('electoraterating',lambda x: pd.Series.mode(x) if len(pd.Series.mode(x))>0 else np.NaN),\n",
    "                                                 SA3_NAME_2016 = pd.NamedAgg('SA3_NAME_2016',lambda x: pd.Series.mode(x) if len(pd.Series.mode(x))>0 else np.NaN),\n",
    "                                                 electorate = pd.NamedAgg('electorate',lambda x: pd.Series.mode(x) if len(pd.Series.mode(x))>0 else np.NaN)\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputate\n",
    "imputation = postcodes_agg.groupby('state', as_index=False).agg(sa3name_mode = pd.NamedAgg('sa3name',lambda x: pd.Series.mode(x) if len(pd.Series.mode(x))>0 else np.NaN),\n",
    "                                                 sa4name_mode = pd.NamedAgg('sa4name',lambda x: pd.Series.mode(x) if len(pd.Series.mode(x))>0 else np.NaN),\n",
    "                                                 electoraterating_mode = pd.NamedAgg('electoraterating',lambda x: pd.Series.mode(x) if len(pd.Series.mode(x))>0 else np.NaN),\n",
    "                                                 SA3_NAME_2016_mode = pd.NamedAgg('SA3_NAME_2016',lambda x: pd.Series.mode(x) if len(pd.Series.mode(x))>0 else np.NaN),\n",
    "                                                 electorate_mode = pd.NamedAgg('electorate',lambda x: pd.Series.mode(x) if len(pd.Series.mode(x))>0 else np.NaN)\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes_agg = postcodes_agg.merge(imputation, on='state', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes_agg.sa3name.fillna(postcodes_agg.sa3name_mode, inplace=True)\n",
    "postcodes_agg.sa4name.fillna(postcodes_agg.sa4name_mode, inplace=True)\n",
    "postcodes_agg.electoraterating.fillna(postcodes_agg.electoraterating_mode, inplace=True)\n",
    "postcodes_agg.SA3_NAME_2016.fillna(postcodes_agg.SA3_NAME_2016_mode, inplace=True)\n",
    "postcodes_agg.electorate.fillna(postcodes_agg.electorate_mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes_agg = postcodes_agg.drop(['sa3name_mode', 'sa4name_mode', 'electoraterating_mode', 'SA3_NAME_2016_mode', 'electorate_mode'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cust = cust.merge(postcodes_agg, on=['postcode', 'state'], how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
